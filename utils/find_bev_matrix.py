import numpy as np
import cv2
from scipy.spatial.transform import Rotation
import argparse
import os

def _annotate_bev_axes(bev_img, x_min, x_max, z_min, z_max, label_x='X', label_z='Z', camera_pos=None):
    """BEV ì´ë¯¸ì§€ì— ëˆˆê¸ˆ/ì¶• ë ˆì´ë¸”ì„ ë³´ê¸° ì¢‹ê²Œ ì˜¤ë²„ë ˆì´í•©ë‹ˆë‹¤."""
    annotated = bev_img.copy()
    height, width = annotated.shape[:2]
    overlay = annotated.copy()

    font = cv2.FONT_HERSHEY_SIMPLEX
    axis_color = (0, 220, 255)
    tick_color = (255, 255, 255)
    grid_color = (80, 80, 80)
    line_thickness = 2

    def to_u(x_world):
        return int(round((x_world - x_min) / (x_max - x_min) * (width - 1)))

    def to_v(z_world):
        return int(round((z_max - z_world) / (z_max - z_min) * (height - 1)))

    # ì‚´ì§ ì–´ë‘ìš´ ë°°ê²½ ë°´ë“œ ì¶”ê°€
    cv2.rectangle(overlay, (0, height - 40), (width - 1, height - 1), (0, 0, 0), -1)
    cv2.rectangle(overlay, (0, 0), (90, height - 1), (0, 0, 0), -1)
    annotated = cv2.addWeighted(overlay, 0.35, annotated, 0.65, 0)

    # 0ì¶• ê°•ì¡°
    if x_min <= 0.0 <= x_max:
        u0 = to_u(0.0)
        cv2.line(annotated, (u0, 0), (u0, height - 1), grid_color, 1, cv2.LINE_AA)
        cv2.putText(annotated, f"{label_x}=0m", (min(u0 + 6, width - 80), min(24, height - 6)), font, 0.5, axis_color, 1, cv2.LINE_AA)

    if z_min <= 0.0 <= z_max:
        v0 = to_v(0.0)
        cv2.line(annotated, (0, v0), (width - 1, v0), grid_color, 1, cv2.LINE_AA)
        cv2.putText(annotated, f"{label_z}=0m", (min(12, width - 80), max(v0 - 8, 20)), font, 0.5, axis_color, 1, cv2.LINE_AA)

    # í•˜ë‹¨ Xì¶• ëˆˆê¸ˆ
    for x_val in np.linspace(x_min, x_max, num=5):
        u = int(np.clip(to_u(x_val), 0, width - 1))
        cv2.line(annotated, (u, height - 14), (u, height - 2), axis_color, 1, cv2.LINE_AA)
        label = f"{x_val:.1f}m"
        text_size = cv2.getTextSize(label, font, 0.45, 1)[0]
        text_x = int(np.clip(u - text_size[0] // 2, 2, width - text_size[0] - 2))
        text_y = height - 4
        cv2.putText(annotated, label, (text_x, text_y), font, 0.45, tick_color, 1, cv2.LINE_AA)

    # ì¢Œì¸¡ Yì¶•(ê¸°ì¡´ Z) ëˆˆê¸ˆ
    for z_val in np.linspace(z_min, z_max, num=5):
        v = int(np.clip(to_v(z_val), 0, height - 1))
        cv2.line(annotated, (6, v), (20, v), axis_color, 1, cv2.LINE_AA)
        label = f"{-z_val:.1f}m"
        text_size = cv2.getTextSize(label, font, 0.45, 1)[0]
        text_y = int(np.clip(v + text_size[1] // 2, text_size[1] + 4, height - 4))
        cv2.putText(annotated, label, (24, text_y), font, 0.45, tick_color, 1, cv2.LINE_AA)

    # ë°©í–¥ ì•ˆë‚´ í™”ì‚´í‘œ
    cv2.arrowedLine(annotated, (width - 100, height - 28), (width - 30, height - 28), axis_color, line_thickness, cv2.LINE_AA, tipLength=0.25)
    cv2.putText(annotated, f"+{label_x}", (width - 95, height - 34), font, 0.55, axis_color, 1, cv2.LINE_AA)

    cv2.arrowedLine(annotated, (50, 70), (50, 20), axis_color, line_thickness, cv2.LINE_AA, tipLength=0.25)
    cv2.putText(annotated, f"-{label_z}", (58, 38), font, 0.55, axis_color, 1, cv2.LINE_AA)

    if camera_pos is not None:
        cam_x, cam_z = camera_pos
        if x_min <= cam_x <= x_max and z_min <= cam_z <= z_max:
            u = to_u(cam_x)
            v = to_v(cam_z)
            cv2.circle(annotated, (u, v), 6, (255, 200, 0), -1, cv2.LINE_AA)
            cv2.circle(annotated, (u, v), 9, (0, 0, 0), 1, cv2.LINE_AA)
            label = 'Camera'
            text_size = cv2.getTextSize(label, font, 0.45, 1)[0]
            text_x = int(np.clip(u - text_size[0] // 2, 5, width - text_size[0] - 5))
            text_y = int(np.clip(v - 10, text_size[1] + 4, height - 4))
            cv2.putText(annotated, label, (text_x, text_y), font, 0.45, (255, 220, 150), 1, cv2.LINE_AA)

    return annotated

def create_bev_with_remap_final(
    image_path,
    resolution,
    fov_x_deg,
    camera_pos_world,   # Carla ì›”ë“œ ì¢Œí‘œê³„ ê¸°ì¤€ ì¹´ë©”ë¼ ìœ„ì¹˜ (X,Y,Z)
    camera_rot_world,   # Carla ì›”ë“œ ì¢Œí‘œê³„ ê¸°ì¤€ ì¹´ë©”ë¼ íšŒì „ (Pitch,Yaw,Roll)
    output_shape,
    output_filepath,
    bev_range_m=None,
    bev_world_bounds=None,
    annotate_axes=True,
    axis_labels=("X", "Z"),
    mark_camera=True
):
    """
    ê²€ì¦ëœ í‘œì¤€ ì¢Œí‘œê³„ ê¸°ë°˜ì˜ 3D Remappingìœ¼ë¡œ BEV ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    img = cv2.imread(image_path)
    if img is None:
        print(f"ì˜¤ë¥˜: ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        return

    img_height, img_width = img.shape[:2]
    if resolution is not None and (resolution[0] != img_width or resolution[1] != img_height):
        print(
            f"ê²½ê³ : ì œê³µëœ resolution {resolution}ê³¼ ì‹¤ì œ ì´ë¯¸ì§€ í¬ê¸° {(img_width, img_height)}ê°€ ë‹¤ë¦…ë‹ˆë‹¤. ì‹¤ì œ í¬ê¸°ë¡œ ë‚´ë¶€ íŒŒë¼ë¯¸í„°ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."
        )

    # 1. íŒŒë¼ë¯¸í„° ì¤€ë¹„
    width, height = img_width, img_height
    bev_width_pixels, bev_height_pixels = output_shape

    # 2. ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„° (K)
    fov_x_rad = np.deg2rad(fov_x_deg)
    fx = (width / 2) / np.tan(fov_x_rad / 2)
    fy = fx
    cx = width / 2
    cy = height / 2
    K = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])

    # 3. Carla ì¢Œí‘œê³„ -> í‘œì¤€ CV ì¢Œí‘œê³„ ë³€í™˜
    # Carla(UE): X(ì•), Y(ì˜¤ë¥¸ìª½), Z(ìœ„) / Pitch(Yì¶•), Yaw(Zì¶•), Roll(Xì¶•)
    # í‘œì¤€ CV: X(ì˜¤ë¥¸ìª½), Y(ì•„ë˜), Z(ì•)
    axes_carla_to_cv = np.array([[0.0, 1.0, 0.0],
                                 [0.0, 0.0, -1.0],
                                 [1.0, 0.0, 0.0]])

    # ì…ë ¥ì„ (ì¢Œìš° X, ì•ë’¤ Y, ë†’ì´ Z) â†’ Carla (X, Y, Z)ë¡œ ë³€í™˜
    cam_pos_input = np.array(camera_pos_world, dtype=np.float64)
    cam_pos_carla = np.array([-cam_pos_input[1], cam_pos_input[0], cam_pos_input[2]], dtype=np.float64)
    cam_pos_cv = axes_carla_to_cv @ cam_pos_carla

    yaw_carla = camera_rot_world[1] + 90.0
    pitch_carla = -camera_rot_world[0]
    roll_carla = camera_rot_world[2]

    rotation_ue = Rotation.from_euler(
        'ZYX',
        [yaw_carla, pitch_carla, roll_carla],
        degrees=True
    )

    R_cam_to_world_carla = rotation_ue.as_matrix()
    R_world_to_cam_carla = R_cam_to_world_carla.T
    R_world_to_cam = axes_carla_to_cv @ R_world_to_cam_carla @ axes_carla_to_cv.T

    t_world_to_cam = -R_world_to_cam @ cam_pos_cv

    # 4. ë°”ë‹¥(Y=0) í‰ë©´ê³¼ ì´ë¯¸ì§€ ì‚¬ì´ì˜ í˜¸ëª¨ê·¸ë˜í”¼ ê³„ì‚°
    r1 = R_world_to_cam[:, 0]
    r3 = R_world_to_cam[:, 2]
    H_ground_to_img = K @ np.column_stack((r1, r3, t_world_to_cam))

    if bev_world_bounds is not None:
        (x_min, x_max), (z_min, z_max) = bev_world_bounds
        bev_width_m = x_max - x_min
        bev_height_m = z_max - z_min
    else:
        if bev_range_m is None:
            raise ValueError("bev_range_m ë˜ëŠ” bev_world_bounds ì¤‘ í•˜ë‚˜ëŠ” ë°˜ë“œì‹œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.")
        bev_width_m, bev_height_m = bev_range_m
        x_min = cam_pos_cv[0] - (bev_width_m / 2.0)
        x_max = x_min + bev_width_m
        z_max = cam_pos_cv[2] + bev_height_m
        z_min = z_max - bev_height_m

    scale_x = bev_width_m / bev_width_pixels
    scale_y = bev_height_m / bev_height_pixels

    H_bev_to_ground = np.array([
        [scale_x, 0.0, x_min],
        [0.0, -scale_y, z_max],
        [0.0, 0.0, 1.0]
    ])

    H_world_to_bev = np.linalg.inv(H_bev_to_ground)
    H_img_to_ground = np.linalg.inv(H_ground_to_img)

    flip_ground_y = np.diag([1.0, -1.0, 1.0])
    H_img_to_ground = flip_ground_y @ H_img_to_ground
    H_world_to_bev = H_world_to_bev @ flip_ground_y

    H_img_to_bev = H_world_to_bev @ H_img_to_ground

    bev_img = cv2.warpPerspective(
        img,
        H_img_to_bev,
        (bev_width_pixels, bev_height_pixels),
        flags=cv2.INTER_LINEAR,
        borderMode=cv2.BORDER_CONSTANT,
        borderValue=(0, 0, 0)
    )

    camera_ground = (cam_pos_cv[0], cam_pos_cv[2])

    if annotate_axes:
        bev_img = _annotate_bev_axes(
            bev_img,
            x_min=x_min,
            x_max=x_max,
            z_min=z_min,
            z_max=z_max,
            label_x=axis_labels[0],
            label_z=axis_labels[1],
            camera_pos=camera_ground if mark_camera else None
        )

    cv2.imwrite(output_filepath, bev_img)
    print(f"\nâœ¨ ìµœì¢… BEV ì´ë¯¸ì§€ê°€ '{output_filepath}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return H_img_to_ground, H_img_to_bev


# --- ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„ ---
if __name__ == "__main__":
    p = argparse.ArgumentParser(description="find_bev_matrix.py")
    p.add_argument("--carla_camera_position", required=True,
                   help="Carla ì›”ë“œ ì¢Œí‘œê³„ ê¸°ì¤€ ì¹´ë©”ë¼ ìœ„ì¹˜ (X_carla, Y_carla, Z_carla)")
    p.add_argument("--carla_camera_rotation", required=True,
                   help="Carla ì›”ë“œ ì¢Œí‘œê³„ ê¸°ì¤€ ì¹´ë©”ë¼ íšŒì „ (Pitch_carla, Yaw_carla, Roll_carla)")
    p.add_argument("--frame_id", type=str, required=True,
                   help="í”„ë ˆì„ ID (ì˜ˆ: cam1)") 
    p.add_argument("--output_dir", type=str, required=True) 
    args = p.parse_args()
    
    # ==============================================================================
    # âš™ï¸ ì‚¬ìš©ìê°€ ìˆ˜ì •í•  íŒŒë¼ë¯¸í„° ì˜ì—­
    # ==============================================================================
    # Carla ì‹œë®¬ë ˆì´í„°ì—ì„œ ì–»ì€ 'ìˆëŠ” ê·¸ëŒ€ë¡œ'ì˜ ê°’ì„ ì…ë ¥í•˜ì„¸ìš”.
    # ì´ì œ ì´ ê°’ì„ ë°”ê¾¸ë©´ ê¸°ëŒ€í•˜ì‹  ëŒ€ë¡œ ì •í™•í•˜ê²Œ ë™ì‘í•©ë‹ˆë‹¤.
    CARLA_CAMERA_POSITION = tuple(map(float, args.carla_camera_position.split(',')))
    CARLA_CAMERA_ROTATION = tuple(map(float, args.carla_camera_rotation.split(','))) 

    # ì›”ë“œ ì ˆëŒ€ ì¢Œí‘œê³„ì—ì„œ ì‚¬ìš©í•  BEV ì»¤ë²„ë¦¬ì§€ (X, Y)
    # í•„ìš”ì— ë§ê²Œ ìµœì†Œ/ìµœëŒ€ ê°’ì„ ì¡°ì •í•˜ì„¸ìš”.
    BEV_WORLD_BOUNDS = ((-50.0, 50.0), (-50.0, 50.0))

    # íŒŒì¼ ê²½ë¡œ
    INPUT_IMAGE_PATH = 'cam8_frame_000020_-45.jpg'
    OUTPUT_BEV_PATH = 'output_bev.jpg'
    OUTPUT_MAT_PATH = args.output_dir
    
    # ê¸°íƒ€ ì„¤ì •
    BEV_OUTPUT_RESOLUTION = (800, 800)
    IMG_RESOLUTION = (1920, 1080)
    H_FOV_DEGREES = 80.0
    
    # ==============================================================================
    # ğŸ› ï¸ ìë™ ê³„ì‚° ì˜ì—­ (ìˆ˜ì • í•„ìš” ì—†ìŒ)
    # ==============================================================================
    H_img_to_ground, H_img_to_bev = create_bev_with_remap_final(
        image_path=INPUT_IMAGE_PATH,
        resolution=IMG_RESOLUTION,
        fov_x_deg=H_FOV_DEGREES,
        camera_pos_world=CARLA_CAMERA_POSITION,
        camera_rot_world=CARLA_CAMERA_ROTATION,
        output_shape=BEV_OUTPUT_RESOLUTION,
        output_filepath=OUTPUT_BEV_PATH,
        bev_world_bounds=BEV_WORLD_BOUNDS,
        annotate_axes=True,
        axis_labels=("X", "Y")
    )
print("\nH_img_to_ground (image -> ground):")
for row in H_img_to_ground:
    print(" ".join(f"{val:.8e}" for val in row))

os.makedirs(OUTPUT_MAT_PATH, exist_ok=True)
save_path = os.path.join(OUTPUT_MAT_PATH, f"{args.frame_id}.txt")
np.savetxt(save_path, H_img_to_ground, fmt="%.8e")

#print("\nH_img_to_bev (image -> BEV pixels):\n", H_img_to_bev)
print("\n--- ëª¨ë“  ì‘ì—… ì™„ë£Œ ---")
